{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "condition_mapping_file = \"../../resources/CCSCM.csv\"\n",
    "procedure_mapping_file = \"../../resources/CCSPROC.csv\"\n",
    "drug_file = \"../../resources/ATC.csv\"\n",
    "\n",
    "condition_dict = {}\n",
    "with open(condition_mapping_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        condition_dict[row['code']] = row['name'].lower()\n",
    "\n",
    "procedure_dict = {}\n",
    "with open(procedure_mapping_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        procedure_dict[row['code']] = row['name'].lower()\n",
    "\n",
    "drug_dict = {}\n",
    "with open(drug_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['level'] == '3.0':\n",
    "            drug_dict[row['code']] = row['name'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from ChatGPT import ChatECNU\n",
    "from ChatGPT import ChatECNU\n",
    "import json\n",
    "\n",
    "def extract_data_in_brackets(input_string):\n",
    "    pattern = r\"\\[(.*?)\\]\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    return matches\n",
    "\n",
    "def divide_text(long_text, max_len=800):\n",
    "    sub_texts = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(long_text):\n",
    "        end_idx = start_idx + max_len\n",
    "        sub_text = long_text[start_idx:end_idx]\n",
    "        sub_texts.append(sub_text)\n",
    "        start_idx = end_idx\n",
    "    return sub_texts\n",
    "\n",
    "def filter_triples(triples):\n",
    "    chatgpt = ChatECNU()\n",
    "    response = chatgpt.chat(\n",
    "        f\"\"\"\n",
    "            I have a list of triples. I want to select 50 most important triples from the list.\n",
    "            The importance of a triple is based on how you think it will help imrpove healthcare prediction tasks (e.g., drug recommendation, mortality prediction, readmission prediction …).\n",
    "            If you think a triple is important, please keep it. Otherwise, please remove it.\n",
    "            You can also add triples from your background knowledge.\n",
    "            The total size of the updated list should be below 50.\n",
    "\n",
    "            triples: {triples}\n",
    "            updates:\n",
    "        \"\"\"\n",
    "        )\n",
    "    # json_string = str(response)\n",
    "    # json_data = json.loads(json_string)\n",
    "    # 修复：直接访问content属性\n",
    "    if response is None:\n",
    "        print(\"警告: ChatECNU返回None，返回原始triples\")\n",
    "        return triples\n",
    "\n",
    "    # filtered_triples = extract_data_in_brackets(json_data['content'])\n",
    "    filtered_triples = extract_data_in_brackets(response.content)\n",
    "    return filtered_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatGPT import ChatECNU\n",
    "import json\n",
    "\n",
    "def graph_gen(term: str, mode: str):\n",
    "    if mode == \"condition\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: systemic lupus erythematosus\n",
    "        updates: [[systemic lupus erythematosus, is an, autoimmune condition], [systemic lupus erythematosus, may cause, nephritis], [anti-nuclear antigen, is a test for, systemic lupus erythematosus], [systemic lupus erythematosus, is treated with, steroids], [methylprednisolone, is a, steroid]]\n",
    "        \"\"\"\n",
    "    elif mode == \"procedure\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: endoscopy\n",
    "        updates: [[endoscopy, is a, medical procedure], [endoscopy, used for, diagnosis], [endoscopic biopsy, is a type of, endoscopy], [endoscopic biopsy, can detect, ulcers]]\n",
    "        \"\"\"\n",
    "    elif mode == \"drug\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: iobenzamic acid\n",
    "        updates: [[iobenzamic acid, is a, drug], [iobenzamic acid, may have, side effects], [side effects, can include, nausea], [iobenzamic acid, used as, X-ray contrast agent], [iobenzamic acid, formula, C16H13I3N2O3]]\n",
    "        \"\"\"\n",
    "    chatgpt = ChatECNU()\n",
    "    response = chatgpt.chat(\n",
    "        f\"\"\"\n",
    "            Given a prompt (a medical condition/procedure/drug), extrapolate as many relationships as possible of it and provide a list of updates.\n",
    "            The relationships should be helpful for healthcare prediction (e.g., drug recommendation, mortality prediction, readmission prediction …)\n",
    "            Each update should be exactly in format of [ENTITY 1, RELATIONSHIP, ENTITY 2]. The relationship is directed, so the order matters.\n",
    "            Both ENTITY 1 and ENTITY 2 should be noun.\n",
    "            Any element in [ENTITY 1, RELATIONSHIP, ENTITY 2] should be conclusive, make it as short as possible.\n",
    "            Do this in both breadth and depth. Expand [ENTITY 1, RELATIONSHIP, ENTITY 2] until the size reaches 100.\n",
    "\n",
    "            {example}\n",
    "\n",
    "            prompt: {term}\n",
    "            updates:\n",
    "        \"\"\"\n",
    "        )\n",
    "    # json_string = str(response)\n",
    "    # json_data = json.loads(json_string)\n",
    "    # 修复：直接访问content属性\n",
    "    if response is None:\n",
    "        print(f\"警告: ChatECNU返回None，当前term: {term}\")\n",
    "        return \"\"\n",
    "\n",
    "    # triples = extract_data_in_brackets(json_data['content'])\n",
    "    triples = extract_data_in_brackets(response.content)\n",
    "    outstr = \"\"\n",
    "    for triple in triples:\n",
    "        outstr += triple.replace('[', '').replace(']', '').replace(', ', '\\t') + '\\n'\n",
    "\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Future work - Including Clinical Notes\n",
    "# import json\n",
    "\n",
    "# with open('../../clinical_notes/subject_text_dict.json', 'r') as f:\n",
    "#     subject_text_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ChatECNU 功能测试脚本\n",
      "==================================================\n",
      "检查运行前提条件...\n",
      "✓ 找到API密钥文件: ../../resources/ecnu.key\n",
      "✓ openai库已安装，版本: 1.97.1\n",
      "\n",
      "==============================\n",
      "开始测试ChatECNU...\n",
      "✓ ChatECNU客户端初始化成功\n",
      "\n",
      "测试1: 简单对话\n",
      "发送消息: 你好，请简单介绍一下你自己。\n",
      "✓ 收到回复: 你好！我是ChatECNU，由华东师范大学开发的智能助手。很高兴为你服务！我可以帮助你解答问题、提供信息、辅助学习等。作为华东师范大学开发的AI，我特别关注教育领域的需求。请问今天有什么可以帮你的吗？\n",
      "\n",
      "测试2: 获取可用模型\n",
      "✓ 可用模型: ['ChatECNU', 'ecnu-embedding-small', 'ecnu-max', 'ecnu-plus', 'ecnu-image', 'DALL-E-3', 'ecnu-vl', 'ecnu-rerank', 'ecnu-reasoner', 'gpt-4', 'ecnu-reasoner-lite', 'educhat-psychology', 'educhat-general', 'ecnu-turbo', 'InnoSpark', 'InnoSpark-R', 'educhat-r1', 'ChatECNU-app', 'educhat-r1-app', 'deepseekv3-app', 'image-app', 'deepseek-chat-app', 'Qwen3-32B-app', 'Qwen2-VL-app']\n",
      "\n",
      "测试3: 设置系统消息\n",
      "✓ 系统消息设置成功，回复: Python是一种简洁易读的高级编程语言，适合快速开发和跨平台应用。\n",
      "\n",
      "🎉 ChatECNU测试完成！\n",
      "\n",
      "✅ 所有测试通过！ChatECNU工作正常。\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from ChatGPT import ChatECNU\n",
    "\n",
    "def test_chatecnu():\n",
    "    \"\"\"测试ChatECNU是否能正常工作\"\"\"\n",
    "    print(\"开始测试ChatECNU...\")\n",
    "    \n",
    "    try:\n",
    "        # 初始化ChatECNU客户端\n",
    "        chat = ChatECNU(model=\"ecnu-max\")\n",
    "        print(\"✓ ChatECNU客户端初始化成功\")\n",
    "        \n",
    "        # 测试1: 简单对话\n",
    "        print(\"\\n测试1: 简单对话\")\n",
    "        test_message = \"你好，请简单介绍一下你自己。\"\n",
    "        print(f\"发送消息: {test_message}\")\n",
    "        \n",
    "        response = chat.chat(test_message)\n",
    "        if response:\n",
    "            print(f\"✓ 收到回复: {response.content}\")\n",
    "        else:\n",
    "            print(\"✗ 未收到回复\")\n",
    "            return False\n",
    "            \n",
    "        # 测试2: 获取可用模型\n",
    "        print(\"\\n测试2: 获取可用模型\")\n",
    "        models = chat.get_available_models()\n",
    "        if models:\n",
    "            print(f\"✓ 可用模型: {models}\")\n",
    "        else:\n",
    "            print(\"✗ 无法获取模型列表\")\n",
    "            \n",
    "        # 测试3: 设置系统消息\n",
    "        print(\"\\n测试3: 设置系统消息\")\n",
    "        chat.clear_messages()\n",
    "        chat.set_system_message(\"你是一个友好的AI助手，请用简洁的方式回答问题。\")\n",
    "        \n",
    "        response2 = chat.chat(\"请用一句话介绍Python编程语言。\")\n",
    "        if response2:\n",
    "            print(f\"✓ 系统消息设置成功，回复: {response2.content}\")\n",
    "        else:\n",
    "            print(\"✗ 系统消息设置失败\")\n",
    "            \n",
    "        print(\"\\n🎉 ChatECNU测试完成！\")\n",
    "        return True\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"✗ 文件未找到错误: {e}\")\n",
    "        print(\"请确保 resources/ecnu.key 文件存在\")\n",
    "        return False\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"✗ 导入错误: {e}\")\n",
    "        print(\"请确保已安装openai库: pip install openai\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ 测试过程中出现错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_prerequisites():\n",
    "    \"\"\"检查运行前提条件\"\"\"\n",
    "    print(\"检查运行前提条件...\")\n",
    "    \n",
    "    # 检查ecnu.key文件\n",
    "    key_file = \"../../resources/ecnu.key\"\n",
    "    if not os.path.exists(key_file):\n",
    "        print(f\"✗ 未找到API密钥文件: {key_file}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"✓ 找到API密钥文件: {key_file}\")\n",
    "    \n",
    "    # 检查openai库\n",
    "    try:\n",
    "        import openai\n",
    "        print(f\"✓ openai库已安装，版本: {openai.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"✗ 未安装openai库，请运行: pip install openai\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ChatECNU 功能测试脚本\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 检查前提条件\n",
    "    if not check_prerequisites():\n",
    "        print(\"\\n前提条件检查失败，请解决上述问题后重试。\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 运行测试\n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    success = test_chatecnu()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n✅ 所有测试通过！ChatECNU工作正常。\")\n",
    "    else:\n",
    "        print(\"\\n❌ 测试失败，请检查配置和网络连接。\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def write_failure_log(term:str,mode:str,error:str=\"ChatECNU returned None\"):\n",
    "\n",
    "    # 记录失败案例\n",
    "            failure_log = {\n",
    "                \"term\": term,\n",
    "                \"mode\": mode,\n",
    "                \"error\": error\n",
    "            }\n",
    "            \n",
    "            # 保存到失败日志文件\n",
    "            log_file = \"../../logs/failed_requests.json\"\n",
    "            os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "            \n",
    "            try:\n",
    "                with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                    failures = json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                failures = []\n",
    "            \n",
    "            failures.append(failure_log)\n",
    "            \n",
    "            with open(log_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(failures, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(f\"❌ 失败记录已保存: {term} ({mode})\")\n",
    "\n",
    "def graph_gen_with_retry(term: str, mode: str, max_retries=3, delay_range=(1, 5)):\n",
    "    \"\"\"带重试机制的graph_gen函数\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = graph_gen(term, mode)\n",
    "            \n",
    "            if result:  # 如果成功获得结果\n",
    "                if attempt > 0:\n",
    "                    print(f\"✅ 重试成功 (第{attempt + 1}次尝试): {term}\")\n",
    "                return result\n",
    "            else:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = random.uniform(*delay_range)\n",
    "                    print(f\"⏳ 第{attempt + 1}次尝试失败，{delay:.1f}秒后重试: {term}\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    print(f\"❌ 所有重试都失败了: {term}\")\n",
    "                    write_failure_log(term,mode)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = random.uniform(*delay_range)\n",
    "                print(f\"⚠️ 第{attempt + 1}次尝试出错，{delay:.1f}秒后重试: {term} - {str(e)}\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"❌ 所有重试都出错了: {term} - {str(e)}\")\n",
    "                write_failure_log(term,mode,str(e))\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [12:32<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(condition_dict.keys()):\n",
    "    file = f'../../graphs/condition/CCSCM/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        continue\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 100:\n",
    "            outstr = graph_gen_with_retry(term=condition_dict[key], mode=\"condition\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=condition_dict[key], mode=\"condition\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [45:40<00:00, 11.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(procedure_dict.keys()):\n",
    "    file = f'../../graphs/procedure/CCSPROC/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        continue\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 150:\n",
    "            outstr = graph_gen_with_retry(term=procedure_dict[key], mode=\"procedure\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=procedure_dict[key], mode=\"procedure\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(drug_dict.keys()):\n",
    "    file = f'../../graphs/drug/ATC5/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 150:\n",
    "            outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "        # continue\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [1:44:38<00:00, 23.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(drug_dict.keys()):\n",
    "    file = f'../../graphs/drug/ATC3/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 150:\n",
    "            outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "        # continue\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphcare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
