{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "condition_mapping_file = \"../../resources/CCSCM.csv\"\n",
    "procedure_mapping_file = \"../../resources/CCSPROC.csv\"\n",
    "drug_file = \"../../resources/ATC.csv\"\n",
    "\n",
    "condition_dict = {}\n",
    "with open(condition_mapping_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        condition_dict[row['code']] = row['name'].lower()\n",
    "\n",
    "procedure_dict = {}\n",
    "with open(procedure_mapping_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        procedure_dict[row['code']] = row['name'].lower()\n",
    "\n",
    "drug_dict = {}\n",
    "with open(drug_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['level'] == '3.0':\n",
    "            drug_dict[row['code']] = row['name'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from ChatGPT import ChatECNU\n",
    "from ChatGPT import ChatECNU\n",
    "import json\n",
    "\n",
    "def extract_data_in_brackets(input_string):\n",
    "    pattern = r\"\\[(.*?)\\]\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    return matches\n",
    "\n",
    "def divide_text(long_text, max_len=800):\n",
    "    sub_texts = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(long_text):\n",
    "        end_idx = start_idx + max_len\n",
    "        sub_text = long_text[start_idx:end_idx]\n",
    "        sub_texts.append(sub_text)\n",
    "        start_idx = end_idx\n",
    "    return sub_texts\n",
    "\n",
    "def filter_triples(triples):\n",
    "    chatgpt = ChatECNU()\n",
    "    response = chatgpt.chat(\n",
    "        f\"\"\"\n",
    "            I have a list of triples. I want to select 50 most important triples from the list.\n",
    "            The importance of a triple is based on how you think it will help imrpove healthcare prediction tasks (e.g., drug recommendation, mortality prediction, readmission prediction ‚Ä¶).\n",
    "            If you think a triple is important, please keep it. Otherwise, please remove it.\n",
    "            You can also add triples from your background knowledge.\n",
    "            The total size of the updated list should be below 50.\n",
    "\n",
    "            triples: {triples}\n",
    "            updates:\n",
    "        \"\"\"\n",
    "        )\n",
    "    # json_string = str(response)\n",
    "    # json_data = json.loads(json_string)\n",
    "    # ‰øÆÂ§çÔºöÁõ¥Êé•ËÆøÈóÆcontentÂ±ûÊÄß\n",
    "    if response is None:\n",
    "        print(\"Ë≠¶Âëä: ChatECNUËøîÂõûNoneÔºåËøîÂõûÂéüÂßãtriples\")\n",
    "        return triples\n",
    "\n",
    "    # filtered_triples = extract_data_in_brackets(json_data['content'])\n",
    "    filtered_triples = extract_data_in_brackets(response.content)\n",
    "    return filtered_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatGPT import ChatECNU\n",
    "import json\n",
    "\n",
    "def graph_gen(term: str, mode: str):\n",
    "    if mode == \"condition\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: systemic lupus erythematosus\n",
    "        updates: [[systemic lupus erythematosus, is an, autoimmune condition], [systemic lupus erythematosus, may cause, nephritis], [anti-nuclear antigen, is a test for, systemic lupus erythematosus], [systemic lupus erythematosus, is treated with, steroids], [methylprednisolone, is a, steroid]]\n",
    "        \"\"\"\n",
    "    elif mode == \"procedure\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: endoscopy\n",
    "        updates: [[endoscopy, is a, medical procedure], [endoscopy, used for, diagnosis], [endoscopic biopsy, is a type of, endoscopy], [endoscopic biopsy, can detect, ulcers]]\n",
    "        \"\"\"\n",
    "    elif mode == \"drug\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: iobenzamic acid\n",
    "        updates: [[iobenzamic acid, is a, drug], [iobenzamic acid, may have, side effects], [side effects, can include, nausea], [iobenzamic acid, used as, X-ray contrast agent], [iobenzamic acid, formula, C16H13I3N2O3]]\n",
    "        \"\"\"\n",
    "    chatgpt = ChatECNU()\n",
    "    response = chatgpt.chat(\n",
    "        f\"\"\"\n",
    "            Given a prompt (a medical condition/procedure/drug), extrapolate as many relationships as possible of it and provide a list of updates.\n",
    "            The relationships should be helpful for healthcare prediction (e.g., drug recommendation, mortality prediction, readmission prediction ‚Ä¶)\n",
    "            Each update should be exactly in format of [ENTITY 1, RELATIONSHIP, ENTITY 2]. The relationship is directed, so the order matters.\n",
    "            Both ENTITY 1 and ENTITY 2 should be noun.\n",
    "            Any element in [ENTITY 1, RELATIONSHIP, ENTITY 2] should be conclusive, make it as short as possible.\n",
    "            Do this in both breadth and depth. Expand [ENTITY 1, RELATIONSHIP, ENTITY 2] until the size reaches 100.\n",
    "\n",
    "            {example}\n",
    "\n",
    "            prompt: {term}\n",
    "            updates:\n",
    "        \"\"\"\n",
    "        )\n",
    "    # json_string = str(response)\n",
    "    # json_data = json.loads(json_string)\n",
    "    # ‰øÆÂ§çÔºöÁõ¥Êé•ËÆøÈóÆcontentÂ±ûÊÄß\n",
    "    if response is None:\n",
    "        print(f\"Ë≠¶Âëä: ChatECNUËøîÂõûNoneÔºåÂΩìÂâçterm: {term}\")\n",
    "        return \"\"\n",
    "\n",
    "    # triples = extract_data_in_brackets(json_data['content'])\n",
    "    triples = extract_data_in_brackets(response.content)\n",
    "    outstr = \"\"\n",
    "    for triple in triples:\n",
    "        outstr += triple.replace('[', '').replace(']', '').replace(', ', '\\t') + '\\n'\n",
    "\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Future work - Including Clinical Notes\n",
    "# import json\n",
    "\n",
    "# with open('../../clinical_notes/subject_text_dict.json', 'r') as f:\n",
    "#     subject_text_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ChatECNU ÂäüËÉΩÊµãËØïËÑöÊú¨\n",
      "==================================================\n",
      "Ê£ÄÊü•ËøêË°åÂâçÊèêÊù°‰ª∂...\n",
      "‚úì ÊâæÂà∞APIÂØÜÈí•Êñá‰ª∂: ../../resources/ecnu.key\n",
      "‚úì openaiÂ∫ìÂ∑≤ÂÆâË£ÖÔºåÁâàÊú¨: 1.97.1\n",
      "\n",
      "==============================\n",
      "ÂºÄÂßãÊµãËØïChatECNU...\n",
      "‚úì ChatECNUÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÊàêÂäü\n",
      "\n",
      "ÊµãËØï1: ÁÆÄÂçïÂØπËØù\n",
      "ÂèëÈÄÅÊ∂àÊÅØ: ‰Ω†Â•ΩÔºåËØ∑ÁÆÄÂçï‰ªãÁªç‰∏Ä‰∏ã‰Ω†Ëá™Â∑±„ÄÇ\n",
      "‚úì Êî∂Âà∞ÂõûÂ§ç: ‰Ω†Â•ΩÔºÅÊàëÊòØChatECNUÔºåÁî±Âçé‰∏úÂ∏àËåÉÂ§ßÂ≠¶ÂºÄÂèëÁöÑÊô∫ËÉΩÂä©Êâã„ÄÇÂæàÈ´òÂÖ¥‰∏∫‰Ω†ÊúçÂä°ÔºÅÊàëÂèØ‰ª•Â∏ÆÂä©‰Ω†Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØ„ÄÅËæÖÂä©Â≠¶‰π†Á≠â„ÄÇ‰Ωú‰∏∫Âçé‰∏úÂ∏àËåÉÂ§ßÂ≠¶ÂºÄÂèëÁöÑAIÔºåÊàëÁâπÂà´ÂÖ≥Ê≥®ÊïôËÇ≤È¢ÜÂüüÁöÑÈúÄÊ±Ç„ÄÇËØ∑ÈóÆ‰ªäÂ§©Êúâ‰ªÄ‰πàÂèØ‰ª•Â∏Æ‰Ω†ÁöÑÂêóÔºü\n",
      "\n",
      "ÊµãËØï2: Ëé∑ÂèñÂèØÁî®Ê®°Âûã\n",
      "‚úì ÂèØÁî®Ê®°Âûã: ['ChatECNU', 'ecnu-embedding-small', 'ecnu-max', 'ecnu-plus', 'ecnu-image', 'DALL-E-3', 'ecnu-vl', 'ecnu-rerank', 'ecnu-reasoner', 'gpt-4', 'ecnu-reasoner-lite', 'educhat-psychology', 'educhat-general', 'ecnu-turbo', 'InnoSpark', 'InnoSpark-R', 'educhat-r1', 'ChatECNU-app', 'educhat-r1-app', 'deepseekv3-app', 'image-app', 'deepseek-chat-app', 'Qwen3-32B-app', 'Qwen2-VL-app']\n",
      "\n",
      "ÊµãËØï3: ËÆæÁΩÆÁ≥ªÁªüÊ∂àÊÅØ\n",
      "‚úì Á≥ªÁªüÊ∂àÊÅØËÆæÁΩÆÊàêÂäüÔºåÂõûÂ§ç: PythonÊòØ‰∏ÄÁßçÁÆÄÊ¥ÅÊòìËØªÁöÑÈ´òÁ∫ßÁºñÁ®ãËØ≠Ë®ÄÔºåÈÄÇÂêàÂø´ÈÄüÂºÄÂèëÂíåË∑®Âπ≥Âè∞Â∫îÁî®„ÄÇ\n",
      "\n",
      "üéâ ChatECNUÊµãËØïÂÆåÊàêÔºÅ\n",
      "\n",
      "‚úÖ ÊâÄÊúâÊµãËØïÈÄöËøáÔºÅChatECNUÂ∑•‰ΩúÊ≠£Â∏∏„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from ChatGPT import ChatECNU\n",
    "\n",
    "def test_chatecnu():\n",
    "    \"\"\"ÊµãËØïChatECNUÊòØÂê¶ËÉΩÊ≠£Â∏∏Â∑•‰Ωú\"\"\"\n",
    "    print(\"ÂºÄÂßãÊµãËØïChatECNU...\")\n",
    "    \n",
    "    try:\n",
    "        # ÂàùÂßãÂåñChatECNUÂÆ¢Êà∑Á´Ø\n",
    "        chat = ChatECNU(model=\"ecnu-max\")\n",
    "        print(\"‚úì ChatECNUÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÊàêÂäü\")\n",
    "        \n",
    "        # ÊµãËØï1: ÁÆÄÂçïÂØπËØù\n",
    "        print(\"\\nÊµãËØï1: ÁÆÄÂçïÂØπËØù\")\n",
    "        test_message = \"‰Ω†Â•ΩÔºåËØ∑ÁÆÄÂçï‰ªãÁªç‰∏Ä‰∏ã‰Ω†Ëá™Â∑±„ÄÇ\"\n",
    "        print(f\"ÂèëÈÄÅÊ∂àÊÅØ: {test_message}\")\n",
    "        \n",
    "        response = chat.chat(test_message)\n",
    "        if response:\n",
    "            print(f\"‚úì Êî∂Âà∞ÂõûÂ§ç: {response.content}\")\n",
    "        else:\n",
    "            print(\"‚úó Êú™Êî∂Âà∞ÂõûÂ§ç\")\n",
    "            return False\n",
    "            \n",
    "        # ÊµãËØï2: Ëé∑ÂèñÂèØÁî®Ê®°Âûã\n",
    "        print(\"\\nÊµãËØï2: Ëé∑ÂèñÂèØÁî®Ê®°Âûã\")\n",
    "        models = chat.get_available_models()\n",
    "        if models:\n",
    "            print(f\"‚úì ÂèØÁî®Ê®°Âûã: {models}\")\n",
    "        else:\n",
    "            print(\"‚úó Êó†Ê≥ïËé∑ÂèñÊ®°ÂûãÂàóË°®\")\n",
    "            \n",
    "        # ÊµãËØï3: ËÆæÁΩÆÁ≥ªÁªüÊ∂àÊÅØ\n",
    "        print(\"\\nÊµãËØï3: ËÆæÁΩÆÁ≥ªÁªüÊ∂àÊÅØ\")\n",
    "        chat.clear_messages()\n",
    "        chat.set_system_message(\"‰Ω†ÊòØ‰∏Ä‰∏™ÂèãÂ•ΩÁöÑAIÂä©ÊâãÔºåËØ∑Áî®ÁÆÄÊ¥ÅÁöÑÊñπÂºèÂõûÁ≠îÈóÆÈ¢ò„ÄÇ\")\n",
    "        \n",
    "        response2 = chat.chat(\"ËØ∑Áî®‰∏ÄÂè•ËØù‰ªãÁªçPythonÁºñÁ®ãËØ≠Ë®Ä„ÄÇ\")\n",
    "        if response2:\n",
    "            print(f\"‚úì Á≥ªÁªüÊ∂àÊÅØËÆæÁΩÆÊàêÂäüÔºåÂõûÂ§ç: {response2.content}\")\n",
    "        else:\n",
    "            print(\"‚úó Á≥ªÁªüÊ∂àÊÅØËÆæÁΩÆÂ§±Ë¥•\")\n",
    "            \n",
    "        print(\"\\nüéâ ChatECNUÊµãËØïÂÆåÊàêÔºÅ\")\n",
    "        return True\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚úó Êñá‰ª∂Êú™ÊâæÂà∞ÈîôËØØ: {e}\")\n",
    "        print(\"ËØ∑Á°Æ‰øù resources/ecnu.key Êñá‰ª∂Â≠òÂú®\")\n",
    "        return False\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚úó ÂØºÂÖ•ÈîôËØØ: {e}\")\n",
    "        print(\"ËØ∑Á°Æ‰øùÂ∑≤ÂÆâË£ÖopenaiÂ∫ì: pip install openai\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó ÊµãËØïËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_prerequisites():\n",
    "    \"\"\"Ê£ÄÊü•ËøêË°åÂâçÊèêÊù°‰ª∂\"\"\"\n",
    "    print(\"Ê£ÄÊü•ËøêË°åÂâçÊèêÊù°‰ª∂...\")\n",
    "    \n",
    "    # Ê£ÄÊü•ecnu.keyÊñá‰ª∂\n",
    "    key_file = \"../../resources/ecnu.key\"\n",
    "    if not os.path.exists(key_file):\n",
    "        print(f\"‚úó Êú™ÊâæÂà∞APIÂØÜÈí•Êñá‰ª∂: {key_file}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"‚úì ÊâæÂà∞APIÂØÜÈí•Êñá‰ª∂: {key_file}\")\n",
    "    \n",
    "    # Ê£ÄÊü•openaiÂ∫ì\n",
    "    try:\n",
    "        import openai\n",
    "        print(f\"‚úì openaiÂ∫ìÂ∑≤ÂÆâË£ÖÔºåÁâàÊú¨: {openai.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"‚úó Êú™ÂÆâË£ÖopenaiÂ∫ìÔºåËØ∑ËøêË°å: pip install openai\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ChatECNU ÂäüËÉΩÊµãËØïËÑöÊú¨\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Ê£ÄÊü•ÂâçÊèêÊù°‰ª∂\n",
    "    if not check_prerequisites():\n",
    "        print(\"\\nÂâçÊèêÊù°‰ª∂Ê£ÄÊü•Â§±Ë¥•ÔºåËØ∑Ëß£ÂÜ≥‰∏äËø∞ÈóÆÈ¢òÂêéÈáçËØï„ÄÇ\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # ËøêË°åÊµãËØï\n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    success = test_chatecnu()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n‚úÖ ÊâÄÊúâÊµãËØïÈÄöËøáÔºÅChatECNUÂ∑•‰ΩúÊ≠£Â∏∏„ÄÇ\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå ÊµãËØïÂ§±Ë¥•ÔºåËØ∑Ê£ÄÊü•ÈÖçÁΩÆÂíåÁΩëÁªúËøûÊé•„ÄÇ\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def write_failure_log(term:str,mode:str,error:str=\"ChatECNU returned None\"):\n",
    "\n",
    "    # ËÆ∞ÂΩïÂ§±Ë¥•Ê°à‰æã\n",
    "            failure_log = {\n",
    "                \"term\": term,\n",
    "                \"mode\": mode,\n",
    "                \"error\": error\n",
    "            }\n",
    "            \n",
    "            # ‰øùÂ≠òÂà∞Â§±Ë¥•Êó•ÂøóÊñá‰ª∂\n",
    "            log_file = \"../../logs/failed_requests.json\"\n",
    "            os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "            \n",
    "            try:\n",
    "                with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                    failures = json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                failures = []\n",
    "            \n",
    "            failures.append(failure_log)\n",
    "            \n",
    "            with open(log_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(failures, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(f\"‚ùå Â§±Ë¥•ËÆ∞ÂΩïÂ∑≤‰øùÂ≠ò: {term} ({mode})\")\n",
    "\n",
    "def graph_gen_with_retry(term: str, mode: str, max_retries=3, delay_range=(1, 5)):\n",
    "    \"\"\"Â∏¶ÈáçËØïÊú∫Âà∂ÁöÑgraph_genÂáΩÊï∞\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = graph_gen(term, mode)\n",
    "            \n",
    "            if result:  # Â¶ÇÊûúÊàêÂäüËé∑ÂæóÁªìÊûú\n",
    "                if attempt > 0:\n",
    "                    print(f\"‚úÖ ÈáçËØïÊàêÂäü (Á¨¨{attempt + 1}Ê¨°Â∞ùËØï): {term}\")\n",
    "                return result\n",
    "            else:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = random.uniform(*delay_range)\n",
    "                    print(f\"‚è≥ Á¨¨{attempt + 1}Ê¨°Â∞ùËØïÂ§±Ë¥•Ôºå{delay:.1f}ÁßíÂêéÈáçËØï: {term}\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    print(f\"‚ùå ÊâÄÊúâÈáçËØïÈÉΩÂ§±Ë¥•‰∫Ü: {term}\")\n",
    "                    write_failure_log(term,mode)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                delay = random.uniform(*delay_range)\n",
    "                print(f\"‚ö†Ô∏è Á¨¨{attempt + 1}Ê¨°Â∞ùËØïÂá∫ÈîôÔºå{delay:.1f}ÁßíÂêéÈáçËØï: {term} - {str(e)}\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"‚ùå ÊâÄÊúâÈáçËØïÈÉΩÂá∫Èîô‰∫Ü: {term} - {str(e)}\")\n",
    "                write_failure_log(term,mode,str(e))\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 285/285 [12:32<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(condition_dict.keys()):\n",
    "    file = f'../../graphs/condition/CCSCM/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        continue\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 100:\n",
    "            outstr = graph_gen_with_retry(term=condition_dict[key], mode=\"condition\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=condition_dict[key], mode=\"condition\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 231/231 [45:40<00:00, 11.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(procedure_dict.keys()):\n",
    "    file = f'../../graphs/procedure/CCSPROC/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        continue\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 150:\n",
    "            outstr = graph_gen_with_retry(term=procedure_dict[key], mode=\"procedure\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=procedure_dict[key], mode=\"procedure\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(drug_dict.keys()):\n",
    "    file = f'../../graphs/drug/ATC5/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 150:\n",
    "            outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "        # continue\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 269/269 [1:44:38<00:00, 23.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for key in tqdm(drug_dict.keys()):\n",
    "    file = f'../../graphs/drug/ATC3/{key}.txt'\n",
    "    if os.path.exists(file):\n",
    "        with open(file=file, mode=\"r\", encoding='utf-8') as f:\n",
    "            prev_triples = f.read()\n",
    "        if len(prev_triples.split('\\n')) < 150:\n",
    "            outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "            outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "            outstr = prev_triples + outstr\n",
    "            # print(outstr)\n",
    "            outfile.write(outstr)\n",
    "        # continue\n",
    "    else:\n",
    "        outstr = graph_gen_with_retry(term=drug_dict[key], mode=\"drug\")\n",
    "        outfile = open(file=file, mode='w', encoding='utf-8')\n",
    "        outstr = outstr\n",
    "        # print(outstr)\n",
    "        outfile.write(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphcare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
